{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c250499a-f277-4cb6-a780-3944d12ea867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e8d9f-4637-4f4c-8fa3-76e93c4cf26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x: float) -> float:\n",
    "    return max(0,x)\n",
    "\n",
    "def ReLU_(x: float) -> float:\n",
    "    '''the derivative of the ReLU function'''\n",
    "    return 1.0 if x > 0.0 else 0.0\n",
    "\n",
    "def softmax(Z: np.ndarray) -> np.ndarray:\n",
    "    S = np.sum(np.exp(Z))\n",
    "    sigma = np.exp(Z)/S\n",
    "    return sigma\n",
    "\n",
    "def CE_loss(y: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "    return -np.dot(y, np.log(y_hat))\n",
    "\n",
    "# in the doc strings for the three partials, only the used arguments are documented\n",
    "def partial_U(H, H_, U, W, V, X, t, y, y_hat):  \n",
    "    '''H: 1D array of the current hidden state of shape (m,)\n",
    "       y: 1D array of the one-hot coded target label of shape (k,)\n",
    "       y_hat: 1D array of the model's predicted probability of each class of shape (k,)'''\n",
    "    delta_out = y_hat - y\n",
    "    return np.outer(H, delta_out)   \n",
    "\n",
    "def partial_W(H, H_, U, W, V, X, t, y, y_hat):\n",
    "    '''H: 1D array of the current hidden state of shape (m,)\n",
    "       X: 2D data array of shape (T, num_features) where T is the total length of the time series\n",
    "       t: specified time step\n",
    "       U: weight matrix connecting the hidden layer to the output layer of shape (m, k)\n",
    "       W: weight matrix connecting the input layer to the hidden layer of shape (m, num_features)\n",
    "       V: recurrent weight matrix of shape (m ,m)\n",
    "       y: 1D array of the one-hot coded target label of shape (k,)'''\n",
    "    vReLU_ = np.vectorize(ReLU_)\n",
    "    scale, delta_out = vReLU_((W @ X[t].T) + (V @ H_)), y_hat - y\n",
    "    m, num_features = U.shape[0], X.shape[1]\n",
    "    result = np.empty((m, num_features))\n",
    "    for j in range(num_features):\n",
    "        result[:,j] = np.sum(U @ delta_out)*scale*X[t][j]\n",
    "    return result \n",
    "   \n",
    "\n",
    "def partial_V(H, H_, U, W, V, X, t, y, y_hat):\n",
    "    '''H_: 1D array of the previous hidden state of shape (m,)\n",
    "       U: weight matrix connecting the hidden layer to the output layer of shape (m, k)\n",
    "       W: weight matrix connecting the input layer to the hidden layer of shape (m, num_features)\n",
    "       V: recurrent weight matrix of shape (m ,m)\n",
    "       y: 1D array of the one-hot coded target label of shape (k,)''' \n",
    "    vReLU_ = np.vectorize(ReLU_)\n",
    "    scale, delta_out = vReLU_((W @ X[t].T) + (V @ H_)), y_hat - y\n",
    "    m, num_features = U.shape[0], X.shape[1]\n",
    "    result = np.empty((m, num_features))\n",
    "    for j in range(num_features):\n",
    "        result[:,j] = np.sum(U @ delta_out)*scale*H_[j]\n",
    "    return result \n",
    "    \n",
    "\n",
    "def mini_batch_GD(data: np.ndarray, alpha, batch_size, num_epochs, epsilon,\n",
    "                  H, H_, U, X, t, y, y_hat, *partials, *weight_inits):\n",
    "    \n",
    "    '''JUST A DRAFT\n",
    "       data: 3D array of shape (num_samples, num_time_steps, num_features)\n",
    "       partials: any number of 2D arrays of partial derivative functions of the paramerters (weights) to update\n",
    "       weight_inits: any number of 2D arrays of weight initializations'''\n",
    "    partials_arr, weights_arr = np.array(partials, dtype=object), np.array(weights_inits, dtype=object)\n",
    "    num_batches = int(data.shape[0]/batch_size)\n",
    "    for epoch in num_epochs:\n",
    "        np.random.shuffle(data)\n",
    "        for i in range(num_batches):\n",
    "            mini_batch = data[i*batch_size:(i+1)*batch_size] # mini_batch is a 3D array of shape (batch_size, num_time_steps, num_features)     \n",
    "            temp = np.zeros(len(partials))\n",
    "            for X in mini_batch: \n",
    "                temp += np.array([p(H, H_, U, W, V, X, t, y, y_hat) for p in partials_arr])\n",
    "            weights_arr -= alpha*temp/batch_size # average over batch size\n",
    "    return weights_arr\n",
    "                \n",
    "            \n",
    "\n",
    "class Input:\n",
    "    def __init__(self, data):\n",
    "        '''data: 3D array of shape (num_samples, num_time_steps, num_features)'''\n",
    "        self.data = data\n",
    "\n",
    "class Hidden:\n",
    "    def __init__(self, input, m, W, V, pre_H, t=1):\n",
    "        '''input: an instance of class Input\n",
    "           m: number of neurons\n",
    "           W: weight matrix connecting the input layer to the hidden layer of shape (m, num_features)\n",
    "           V: recurrent weight matrix of shape (m ,m)\n",
    "           pre_H: 2D array of shape (num_samples, m)\n",
    "           t: initialized time step, which typically starts from 1'''\n",
    "        self.input = input\n",
    "        self.m = m\n",
    "        self.W = W\n",
    "        self.V = V\n",
    "        self.pre_H = pre_H\n",
    "        self.t = t\n",
    "        # current_H not set as an attribute in initialization because the first step (t=1) of the iteration\n",
    "        # does not need the current hidden state to be set\n",
    "    def get_current_state(self):  \n",
    "        data, pre_H, W, V, t = self.input.data, self.pre_H, self.W, self.V, self.t\n",
    "        num_samples, m = pre_H.shape\n",
    "        current_H = np.array([np.array([ReLU(np.dot(W[i], data[j][t])\n",
    "                                           + np.dot(V[i], pre_H[j])) for i in range(m)])\n",
    "                                                                     for j in range(num_samples)]).reshape(num_samples, m)    \n",
    "        \n",
    "        self.pre_H, self.current_H = current_H, current_H\n",
    "        self.t += 1 # updates current time\n",
    "\n",
    "class Output:\n",
    "    def __init__(self, hidden, y, k, U, T): \n",
    "        '''hidden: an instance of class Hidden\n",
    "           y: 2D one-hot coded target labels array of shape (num_samples, num_classes)\n",
    "           k: number of classes = number of neurons in the output layer\n",
    "           U: weight matrix connecting the hidden layer to the output layer of shape (m, k)\n",
    "           T: total length of the time series/sequence'''\n",
    "        self.hidden = hidden\n",
    "        self.y = y \n",
    "        self.k = k\n",
    "        self.U = U\n",
    "        self.T = T \n",
    "\n",
    "    def get_yhat(self):\n",
    "        hidden, T, U = self.hidden, self.T, self.U\n",
    "        num_samples, m = hidden.pre_H.shape\n",
    "        yhat = np.empty((num_samples, T, self.k))\n",
    "        for i in range(num_samples):\n",
    "            for j in range(T):\n",
    "                hidden.get_current_state()\n",
    "                yhat[i][j] = softmax(hidden.current_H[i] @ U)\n",
    "        self.yhat = yhat\n",
    "    \n",
    "    \n",
    "   # def compute_loss(self):\n",
    "        #self.get_prediction()\n",
    "        #self.loss = CE_loss(self.y, self.prediction)\n",
    "        \n",
    "   # def update_weights(self, alpha, num_epochs, max_iter):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
