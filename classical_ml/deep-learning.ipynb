{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870fa06d-25e3-40a5-aad9-2163c56f0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from operator import add\n",
    "from random import shuffle, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0bdafe89-1192-47e9-9722-d5163e569716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vsigmoid(Z: np.ndarray) -> np.ndarray:\n",
    "    '''Z can be a Numpy array of any shape; 2D in the case of this application'''\n",
    "    return 1/(1 + np.exp(-Z))\n",
    "\n",
    "def softmax(Z: np.ndarray) -> np.ndarray:\n",
    "    '''Z is a 1D Numpy array'''\n",
    "    return np.exp(Z)/np.sum(np.exp(Z))\n",
    "\n",
    "class Input:\n",
    "    def __init__(self, X, W, b):\n",
    "        '''X.shape = (n, d), n number of samples; d number of features\n",
    "           W.shape = (d, h), h number of neurons in the hidden layer\n",
    "           b.shape = (1, h), when b is added to X @ W, b will be broadcasted into shape (n, h)'''\n",
    "        self.X = X\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "       \n",
    "    def to_hidden(self):\n",
    "        return self.X @ self.W + self.b\n",
    "\n",
    "class Hidden:\n",
    "    def __init__(self, Z, W, b):\n",
    "        '''Z.shape = (n, h)\n",
    "           W.shape = (h, c), c number of classes\n",
    "           b.shape = (1, c), will also be broadcasted into shape (n, c)'''\n",
    "        self.Z = Z # Hidden.Z is the pre-activation output of the Input layer, i.e., Hidden.Z = Input.X @ Input.W + Input.b\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "\n",
    "    def activation(self):\n",
    "        return vsigmoid(self.Z)\n",
    "\n",
    "    def to_output(self, A): # A is the post-activation output of the hidden layer, i.e., A = vsigmoid(Hidden.Z)\n",
    "        return A @ self.W + self.b\n",
    "\n",
    "class Output:\n",
    "    def __init__(self, Z):\n",
    "        '''Z.shape = (n, c)'''\n",
    "        self.Z = Z # Output.Z is the pre-activation output of the Hidden layer, i.e., A @ Hidden.W + Hidden.b, where A = vsigmoid(Hidden.Z)\n",
    "\n",
    "    def activation(self):\n",
    "        return np.apply_along_axis(softmax, 1, self.Z)\n",
    "        \n",
    "def adam(alpha, beta1, beta2, epsilon, theta, g, m, v, t):\n",
    "    '''alpha, beta1, beta2, epsilon are hyperparameters; all hyperparameters should be passed as floats\n",
    "       theta is the parameter to be updated with the algorithm\n",
    "       g: gradient of theta'''   \n",
    "    m = beta1 * m + (1 - beta1) * g\n",
    "    v = beta2 * v + (1 - beta2) * (g ** 2)\n",
    "    m_hat = m / (1 - beta1**t)\n",
    "    v_hat = v / (1 - beta2**t)\n",
    "    theta = theta - alpha * m_hat / (np.sqrt(v_hat) + epsilon)  \n",
    "    return m, v, theta\n",
    "\n",
    "def loss_func(Y: np.ndarray, A: np.ndarray, a_min=1e-4) -> float:\n",
    "    '''Y.shape = (n, d), Y is the correct label array\n",
    "       A.shape = (n, d), A is the output probability array at the output layer\n",
    "    '''\n",
    "    A_clipped = np.clip(A, a_min=a_min, a_max=1.0)\n",
    "    return np.mean(-np.sum(Y*np.log(A_clipped), axis=1))\n",
    "\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, X, Y, W2, b2, W1, b1):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.W2 = W2\n",
    "        self.b2 = b2\n",
    "        self.W1 = W1\n",
    "        self.b1 = b1\n",
    "\n",
    "    def forward(self, batch, W2, b2, W1, b1):\n",
    "        input_layer = Input(batch, W1, b1)\n",
    "        Z1 = input_layer.to_hidden()\n",
    "        hidden_layer = Hidden(Z1, W2, b2)\n",
    "        A1 = hidden_layer.activation()\n",
    "        Z2 = hidden_layer.to_output(A1)\n",
    "        output_layer = Output(Z2)\n",
    "        A2 = output_layer.activation()\n",
    "        return A1, A2\n",
    "\n",
    "    def train(self, alpha, beta1, beta2, epsilon, batch_size, p=0, max_epochs=500, threshold=1e-3):  \n",
    "        N = int(self.X.shape[0]/batch_size) # N = number of batches\n",
    "        params = [self.W2, self.b2, self.W1, self.b1]\n",
    "        means = [np.zeros_like(self.W2), np.zeros_like(self.b2), np.zeros_like(self.W1), np.zeros_like(self.b1)]\n",
    "        variances = [np.zeros_like(self.W2), np.zeros_like(self.b2), np.zeros_like(self.W1), np.zeros_like(self.b1)]\n",
    "        \n",
    "        t, loss_pre = 1, float('inf')       \n",
    "        for epoch in range(max_epochs):    \n",
    "            # divide the dataset (X and Y) and randomly shuffle it (make sure to shuffle Y correspondingly)\n",
    "            XY = list(zip([self.X[_*batch_size:(_+1)*batch_size] for _ in range(N)], [self.Y[_*batch_size:(_+1)*batch_size] for _ in range(N)]))\n",
    "            shuffle(XY)\n",
    "            \n",
    "            loss = 0\n",
    "            gradients = [np.zeros_like(self.W2), np.zeros_like(self.b2), np.zeros_like(self.W1), np.zeros_like(self.b1)]\n",
    "            for batch, label in XY:               \n",
    "                A1, A2 = self.forward(batch, params[0], params[1], params[2], params[3])\n",
    "                # this part does thedropout\n",
    "                h = A1.shape[1]\n",
    "                num = int(h*p)\n",
    "                to_drop = sorted(sample(range(h), num))\n",
    "                mask = np.ones_like(A1)\n",
    "                mask[:,to_drop] = 0\n",
    "                A1 *= mask  \n",
    "                A1 *= 1/(1-p)\n",
    "                \n",
    "                loss += loss_func(label, A2)\n",
    "        \n",
    "                partial_Z2 = A2 - label\n",
    "                partial_W2 = A1.T @ partial_Z2\n",
    "                partial_b2 = np.mean(partial_Z2, axis=0, keepdims=True) # average across batch to maintain the shape of b2\n",
    "                partial_A1 = partial_Z2 @ params[0].T # params[0] = W2\n",
    "                partial_Z1 = partial_A1 * (A1 * (1 - A1))\n",
    "                partial_W1 = batch.T @ partial_Z1\n",
    "                partial_b1 = np.mean(partial_Z1, axis=0, keepdims=True) # average across batch to maintain the shape of b1\n",
    "                gradients = list(map(add, gradients, [partial_W2, partial_b2, partial_W1, partial_b1]))\n",
    "\n",
    "                t += 1\n",
    "                \n",
    "            loss = loss/N\n",
    "            if abs(loss - loss_pre) < threshold:\n",
    "                break\n",
    "            loss_pre = loss\n",
    "            \n",
    "            gradients = list(map(lambda x: x/N, gradients))        \n",
    "            for i, param in enumerate(params):\n",
    "                means[i], variances[i], params[i] = adam(alpha, beta1, beta2, epsilon, param,\n",
    "                                                         gradients[i], means[i], variances[i], t)\n",
    "\n",
    "        W2_hat, b2_hat, W1_hat, b1_hat = params\n",
    "        return W2_hat, b2_hat, W1_hat, b1_hat\n",
    "\n",
    "    def predict(self, test_data, W2_hat, b2_hat, W1_hat, b1_hat):\n",
    "        A1, A2 = self.forward(test_data, W2_hat, b2_hat, W1_hat, b1_hat)\n",
    "        argmax_indices = np.argmax(A2, axis=1)\n",
    "        y_hat = np.zeros_like(A2)\n",
    "        y_hat[[_ for _ in range(len(A2))], list(argmax_indices)] = 1\n",
    "        return y_hat\n",
    "\n",
    "    def score_accuracy(self, y_hat, y_test):\n",
    "        argmax_hat, argmax_test = np.argmax(y_hat, axis=1), np.argmax(y_test, axis=1)\n",
    "        return list(argmax_hat == argmax_test).count(True)/len(y_test)\n",
    "\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6f0ec022-a667-47a0-9319-8ed7fcf3b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92e0158b-2e29-48cc-b881-d03ee551126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (120, 3)\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(y.reshape(-1,1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train = (X_train - np.mean(X_train, axis=0))/np.std(X_train, axis=0)\n",
    "X_test = (X_test - np.mean(X_test, axis=0))/np.std(X_test, axis=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b90c33e-05a4-4349-b3a8-d65d71f5aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d, h, c, batch_size = 120, 4, 6, 3, 20\n",
    "W2, b2, W1, b1 = np.random.rand(h,c), np.random.rand(1,c), np.random.rand(d,h), np.random.rand(1,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "609da597-10c8-4bec-8563-e8f32819b478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "alpha, beta1, beta2, epsilon = 0.001, 0.9, 0.999, 1e-7\n",
    "network = Network(X_train, y_train, W2, b2, W1, b1)\n",
    "W2_hat, b2_hat, W1_hat, b1_hat = network.train(alpha, beta1, beta2, epsilon, batch_size, p=0.1)\n",
    "\n",
    "y_hat = network.predict(X_test, W2_hat, b2_hat, W1_hat, b1_hat)\n",
    "accuracy = network.score_accuracy(y_hat, y_test)\n",
    "print(f'Accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb3ccf1-b4ad-4ec6-b385-f55cd9b52d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b07ec79-0a07-41f8-9d23-ab8a83f25cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "59a406f1-3753-4305-a7b6-132bd438a607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13) (142, 3)\n"
     ]
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(y.reshape(-1,1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "X_train = (X_train - np.mean(X_train, axis=0))/np.std(X_train, axis=0)\n",
    "X_test = (X_test - np.mean(X_test, axis=0))/np.std(X_test, axis=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "60cca7ed-8cd4-45a6-8f47-ab79d315835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d, h, c, batch_size = 142, 13, 12, 3, 71\n",
    "W2, b2, W1, b1 = np.random.rand(h,c), np.random.rand(1,c), np.random.rand(d,h), np.random.rand(1,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "16269928-fdb5-43a7-b860-7c28208b41e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "alpha, beta1, beta2, epsilon = 0.001, 0.9, 0.999, 1e-7\n",
    "network = Network(X_train, y_train, W2, b2, W1, b1)\n",
    "W2_hat, b2_hat, W1_hat, b1_hat = network.train(alpha, beta1, beta2, epsilon, batch_size, p=0.2)\n",
    "\n",
    "y_hat = network.predict(X_test, W2_hat, b2_hat, W1_hat, b1_hat)\n",
    "accuracy = network.score_accuracy(y_hat, y_test)\n",
    "print(f'Accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735c9c0-1559-484b-96d6-29708d9552ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc15bd-6066-4bd0-9a56-fa9c17f625ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
